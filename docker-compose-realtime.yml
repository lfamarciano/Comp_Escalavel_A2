# docker-compose.yml
# Define e orquestra toda a pilha de serviÃ§os com um Ãºnico ficheiro.
# > docker-compose up --build --scale producer=2

version: '3.8'

networks:
  app-net:
    driver: bridge

volumes:
  postgres-data:
    driver: local

services:

  spark-consumer:
    build:
      context: .
      target: app-spark
    networks: [app-net]
    container_name: spark_consumer
    environment:
      PIPELINE_ENV: ${PIPELINE_ENV}
    command: >
      /opt/spark/bin/spark-submit
      --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0
      --master local[*]
      spark_consumer.py
